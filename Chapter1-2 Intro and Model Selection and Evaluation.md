<h2>模型评估与选择</h2>

<h4>1. 为什么要进行模型的评估与选择？</h4>

学习器可能会出现欠拟合（underfitting）和过拟合（overfitting）现象。如何选择一个合适的模型来学习数据集的特征，避免出现欠拟合和过拟合的现象？如何选择模型的合适参数配置？我们需要有评估模型的方法，才能更好的进行模型或参数的选择。

<h4>2. 评估方法</h4>

我们通常把分类错误的样本数占样本总数的比例成为“错误率”（error rate）。学习器在训练集（training set）上的误差叫做“训练误差”（training error），在新样本上的误差称为”泛化误差“（generalization error）。通常我们会从新样本中抽取部分学习器从未见过的新样本构成测试集（testing set）。学习器在测试数据集上的误差叫做”测试误差“（test error），通常用测试误差作为泛化误差的近似。

当我们只有一个包含m个样例的数据集D={(x_1, y_1), ..., (x_m, y_m)}，既要训练又要测试，如何进行划分呢？为了进行模型的评估和选择、参数调节，我们还会从原本的训练集中再划分出一个用于评估测试的数据集，这个数据集被称为“验证集”（validation set）。

<h5>2.1 留出法</h5>

将数据集D划分成两个互斥的集合。训练集和测试集的划分应该尽可能保持数据分布的一致性，可采用比如“分层采样”的方法。

<h5>2.2 交叉验证法</h5>

先将数据集D划分成k个大小相似的互斥子集，每个子集D_i尽可能保持数据分布的一致性。然后每次用k-1个子集的并集作为训练集，剩下那个子集作为测试集。这样可获得k组训练/测试集，进行k次训练和测试，最终返回的是这k个测试结果的均值。

<h5>2.3 自助法</h5>

自助法直接以自助采样法为基础。给定包含m个样本的数据集D，我们对它进行采样产生数据集D：每次随机从D中挑选一个样本，将其拷贝放入D，然后再将该样本放回初始数据集D中，使得该样本在下次采样时仍有可能被采到；重复执行次后得到了包含m个样本的数据集D。自助法在数据集较小、难以有效划分训练/测试集时很有用；此外，自助法能从初始数据集中产生多个不同的训练集，这对集成学习等方法有很大的好处。然而自助法产生的数据集改变了初始数据集的分布，会引入估计偏差。

<h4>3. 性能评估</h4>

<h5>3.1 错误率和精度</h5>

E(f;D)=\frac{1}{m}\sum^m_{i=1}I(f(x_i)\neq y_i)

acc(f;D)=\frac{1}{m}\sum^m_{i=1}I(f(x_i)= y_i)=1-E(f;D)

<h5>3.2 查全率、查准率与F1</h5>

P = \frac{TP}{TP+FP}

R = \frac{TP}{TP+FN}

如果一个学习器的P-R曲线被另一个学习器的曲线完全“包住”，则可断言后者性能优于前者。如果两个学习器的P-R曲线发生了较差，难以判断孰优孰劣。

“平衡点”（Breaking-Event Point，简称BEP）是指“查全率=查准率”时的取值。它和F1度量一样可以综合考察查准率和查全率，F1度量更常用.

F1 = \frac{2\times P \times R}{P+R}=\frac{2\times TP}{样本总数+TP-TN}

更一般的形式如下，可以根据对查准率和查全率的不同偏好进行权重的调整

F_\beta=\frac{(1+\beta^2)\times P\times R}{(\beta^2\times P)+R}

<h5>3.3 ROC与AUC</h5>

ROC全称是“受试者工作特征”曲线。横轴是“假正例率”（FPR），纵轴是“真正例率”（TPR）。

TPR = \frac{TP}{TP+FN}

FPR=\frac{FP}{TN+FP}

当一个学习器的ROC曲线被另一个学习器的曲线完全“包住”，则后者性能优于前者；若两个学习器的ROC曲线发生交叉，则难以一般性地判断两者孰优孰劣。此时比较ROC曲线下的面积，即AUC（Area Under ROC Curce）。

<h4>4. 比较检验</h4>

TODO

<h4>5. 偏差与方差</h4>

“偏差-方差分解”（bias-variance decomposition）是解释学习算法泛化性能的一种重要工具。偏差度量了学习算法的期望预测与真实结果的偏离程度，即刻画了学习算法本身的拟合能力；方差度量了同样大小的训练集的变动所导致的学习性能的变化，即可化了数据扰动所造成的影响。噪声则表达了在当前任务上任何学习算法所能达到的期望泛化误差下界，即刻画了学习问题本身的难度。

偏差和方差是有冲突的，即bias-variance dilemma。训练不足时，学习器拟合能力不强，训练数据的扰动不足以使学习器产生显著变化，此时偏差主导了泛化错误率；随着训练程度加深，学习器拟合能力逐渐增强，训练数据发生的扰动渐渐能被学习器学习到，方差逐渐主导了泛化错误率。


<h4>参考文献</h4>

[1] 机器学习及其应用[M]. 清华大学出版社有限公司, 2006.
